// Copyright 2018-2022 The Khronos Group. This work is licensed under a
// Creative Commons Attribution 4.0 International License; see
// http://creativecommons.org/licenses/by/4.0/
= cl_khr_defined_builtin_kernels =

:source-highlighter: coderay

[[cl_khr_defined_builtin_kernels]]
== Khronos-Defined Built-in Kernels (Early Draft)

The purpose of this extension is to provide a standardized set of built-in
kernels with well-defined semantics useful for accelerating applications
from various domains.  The extension specification is designed to rapidly
expand and "live" via addition of new well-defined built-in kernel
definitions and updating of previously defined ones.

=== General Information

==== Name Strings

`cl_khr_defined_builtin_kernels`

==== Version History

[cols="1,1,3",options="header",]
|====
| *Date*     | *Version* | *Description*
| 2022-12-13 | 0.1.0     | First formulation as an extension specification like proposed by Ben Ashbaugh.
| 2023-11-23 | 0.2.0     |
Add APIs for defined built-in kernel (DBK) creation. Model DBKs on
tensor type. Add sample code.
|====

==== Dependencies

This extension is written against the OpenCL Specification version 3.0.12.

This extension requires OpenCL 1.2 or later.

This extension requires cl_exp_tensor.

==== Contributors

Pekka Jääskeläinen, Intel and Tampere University. +
Topi Leppänen, Tampere University. +
Jan Solanti, Tampere University. +
Ben Ashbaugh, Intel. +
Henry Linjamäki, Intel. +

=== Overview

OpenCL 1.2 specifies a built-in kernel as a kernel that is executed on
an OpenCL device or custom device by fixed-function hardware or in firmware.
Applications can query the built-in kernels supported by a device or custom
device.

Built-in kernels are referred to by a name (a C string) without any
semantics attached to the functionality. The semantics behind the name
is completely device specific, typically documented in vendor-specific
extension specifications.

The goal for this extension is to lower the bar for utilizing hardware
accelerated functions in drivers by providing a library of
well-defined built-in kernel with good coverage for common acceleration needs
and which is designed to easily evolve over time.

The device drivers that implement this extension can freely choose which
subset of defined built-in-kernels (DBKs) they implement and advertise to the clients. The
clients can use the DBKs to accelerate their applications by manually
executing invoking the DBKs. The extension is designed to also support using
automated task graph lowering tooling later.

==== Background

ASIC-based coarse-grained hardware accelerators are specialized logic meant to
speed up execution of workloads of interest, or to provide improvements in
energy-efficiency. Examples of contemporary workloads that are beneficially hardware
accelerated over software-based implementations include video coding, deep learning,
cryptography, software-defined radio and graphics rendering.

FPGAs form a special case somewhere between instruction-set architectures and fixed
function hardware accelerators. While advances in high-level synthesis tools
have attempted to bridge the programmability gap between GPU and FPGA programming,
FPGAs are still considered as devices which are challenging to achieve efficient
implementations with. Due to extensive manual optimization work required for efficient
implementations of the accelerated functionality, defining FPGA designs as
a system of "hardware accelerator IPs" is still a widely used "application abstraction".
FPGAs can be thus seen as a platform that can realize and integrate any
hardware accelerator implementable with the programmable fabric.

The means to utilize hardware accelerators have typically been
vendor-specific and abstracted behind domain-specific libraries.
The overhead with the "bunch of libraries"-approach is seen in the lowest level
of integration: The libraries utilize a low level library (typically
vendor-specific) to interface with the actual hardware, and thus does not
integrate efficiently with other libraries or software-programmable processors
that might be available on the same chip.

==== Rationale

OpenCL's built-in kernel abstraction allows pushing both hardware
accelerated and software defined kernels to the same command-queues,
providing a powerful means for asynchronous execution of heterogeneous
task graphs on diverse heterogeneous platforms. The ability to invoke hardware
accelerators while being able to synchronize and optimize data transfers at
the lowest levels of the driver stack can provide significant latency benefits,
especially when combined with the command-buffering mechanism.

However, the built-in kernel abstraction works well only when it is widely adopted by
vendors, and when multiple vendors implement the same definitions. Otherwise
each vendor specifies and implements their own built-in kernels closely matching their
own hardware accelerator properties, resulting in lack of cross-vendor
portability in the API abstraction presented to the upper layers of
heterogeneous computing software stacks.

This extension standardizes a set of well-defined built-in kernels the
clients can call from higher level programming stacks built with
different languages and multiple libraries, possibly mix accelerator
calls with calls to software kernel commands, and rely on the driver
stack to optimize the execution (especially the synchronization and
communication) as a low level heterogeneous task graph.  The
heterogeneous task graph can be described using multiple
command-queues and optionally cached using the command buffer
extension (cl_khr_command_buffer).  It aims to promote the use of
built-in kernels as a programming model for hardware accelerated
functionality, to improve cross-vendor portability of hardware
accelerated computing.


=== Add new section X.Y.Z Querying Defined Built-in Kernels

To request a defined built-in kernel to be executed in the given
devices use:

[source,c]
----
cl_dbk_descriptor clCreateDefinedBuiltInKernelDescriptor(
    cl_context context,
    cl_uint num_devices,
    const cl_device_id* device_list,
    cl_dbk_name kernel_name,
    const void *kernel_attributes,
    const cl_dbk_mode_properties* kernel_config,
    cl_int *errcode_ret);
----

* _context_ must be a valid OpenCL context.

* _num_devices_ is the number of devices listed in
  device_list. _num_devices_ must be non-zero.

* _device_list_ is a pointer to a list of devices that are in
  context. _device_list_ must be a non-NULL value. The defined built-in kernels
  are loaded for devices specified in this list.

* _kernel_name_ is the name of the defined built-in kernel listed in Appendix I.

* _kernel_attributes_ is a pointer to the structure declared in
  description of the kernel in Appendix I. The structure holds
  kernel's attributes.

* _cl_dbk_mode_properties_ is a pointer to a list of defined built-in
  kernel mode properties. The supported mode properties are listed in
  DBK's entry with default settings in Appendix I. It is valid to set
  this argument to NULL in which case default properties apply (if
  any).

*clCreateDefinedBuiltInKernelDescriptor* returns a valid kernel
descriptor on success indicated by _errcode_ret_ which is set to
CL_SUCCESS. Otherwise, the returned object is NULL and the
_errcode_ret_ is set to one of following code:

* CL_DBK_INVALID_ATTRIBUTE if one or more kernel attributes violates
  conditions descried in defined built-in kernel entry in Appendix I.

* CL_DBK_UNAVAILABLE if kernel attributes are valid but the
  kernel is not supported on one of the devices.

* CL_DBK_UNSUPPORTED_MODE_PROPERTY if _cl_dbk_mode_properties_ includes
  at least one property not listed in DBK's entry.

* CL_DBK_UNMET_MAX_RELATIVE_ERROR if the DBK is available but does not
  meet the requested constraint set by
  CL_DBK_PROPERTY_MAX_RELATIVE_ERROR property.

[cols="2,1,2",stripes=odd]
|===
| *DBK Mode Property* | *Property Value* | *Description*

| CL_DBK_PROPERTY_MAX_RELATIVE_ERROR | float

a| Require that the DBK produces the results which do not deviate more
than the given amount value of ULPs (units in the last place) respect
to infnitely precise result.

| CL_DBK_PROPERTY_NON_DETERMINISTIC | cl_bool

a| Allow results of the kernel to be non-reproducible. This allows
implementation to switch algorithm of the kernel on each launch for
possibly better performance.
// Idea from https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking

|===

=== Add new function to 5.8.1 Creating Program Objects

To create a program with a set of defined built-in kernel use:

[source,c]
----
cl_program clCreateProgramWithDefinedKernels(
    cl_context context,
    size_t num_kernel_desc,
    const void* kernel_desc_list,
    cl_int* errcode_ret);
----

* _context_ must be a valid OpenCL context.

* _num_kernel_desc_ is the number of kernel descriptors.

* _kernel_desc_list_ is the array of valid
  cl_dbk_descriptor objects. The array length must be at
  least _num_kernel_desc_. The kernel descriptors must be created on
  the same context.

*clCreateProgramWithDefinedKernels* returns a valid program on success
indicated by _errcode_ret_ which is set to CL_SUCCESS. Otherwise, the
returned object is NULL and the _errcode_ret_ is set to one of
following code:

* TODO.

=== Add new function to 5.9.1 Creating Kernel Objects

To get a kernel handle for a defined built-in kernel in a program use:

[source,c]
----
cl_kernel clCreateDefinedBuiltInKernel(
    cl_program program,
    cl_dbk_descriptor kernel_desc,
    cl_int* errcode_ret);
----

* _program_ is a program object with a successfully built executable.

* _kernel_desc_ is a defined built-in kernel descriptor in the program.

* _errcode_ret_ will return an appropriate error code. If errcode_ret is
  NULL, no error code is returned.

*clCreateDefinedBuiltInKernel* returns a valid non-zero kernel object
 and errcode_ret is set to CL_SUCCESS if the kernel object is created
 successfully. Otherwise, it returns a NULL value with one of the
 following error values returned in _errcode_ret_:

* TODO.


=== Add new appendix "Appendix I - Defined Built-in Kernels" to OpenCL API Specification

This chapter describes standard defined built-in kernels (DBK) with
well-defined semantics. Devices can report
availability of the built-in kernels listed in this section with
`clCreateDefinedBuiltInKernelDescriptor` call. The availability of a
DBK is determined from the arguments passed to the
`clCreateDefinedBuiltInKernelDescriptor` and unavailability of a DBK
is indicated by CL_DBK_UNAVAILABLE error code.

The general client-side abstraction of the DBKs is similar to a call
to a C function of which implementation is hidden. The device driver
are free to implement a DBK by invoking one or more coarse and fine grained hardware accelerators combined with
firmware to implement the semantics as efficiently as possible.

It is the driver's responsibility to handle efficient synchronization and communication
to the hardware accelerator, the internal accelerator state management and resource sharing
across multiple OpenCL contexts.

==== Reproducibility ====

Identical DBKs or same DBKs executed repeatedly with identical inputs are
guaranteed to produce identical results, unless otherwise stated in
the DBK's description, when:

* enqueued to the same device,

* on the same platform,

* on the same vendor with the same driver version and

* CL_DBK_PROPERTY_NON_DETERMINISTIC property is not set on.

Two DBK descriptors for a device are considered identical if they are created
using identical kernel name, kernel attribute and kernel mode property
arguments. In other cases, identical and inputs may produce different
results. The result difference may occur because, for example,
different algorithms being used across devices.

DBKs may produce approximated results and the error, respect to
infinitely precise result, can be optionally controlled by
CL_DBK_PROPERTY_MAX_RELATIVE_ERROR when the property name is listed in
the DBK's description. DBKs without CL_DBK_PROPERTY_MAX_RELATIVE_ERROR
property produces exact result.

==== The Defined Built-in Kernels ====

The following is list of recognized defined built-in kernels. It is
expected to be expanded and updated over the versions of this extensions, while preserving backwards compatibility.

Each defined built-in kernel entry is organized as follows:

* *Name*: Name of the defined built-in kernel (an enumeration).

* *Kernel attributes*: The kernel attributes required for creating the
  defined built-in kernel via
  clCreateDefinedBuiltInKernelDescriptor. Attribute values are
  immutable.

* *Kernel arguments*: The kernel arguments.

* *Description*: The description of the kernel in detail.

* *Attribute validation rules*: Conditions of the kernel attribute for
  the kernel. Implementation must return CL_DBK_INVALID_ATTRIBUTE on
  clCreateDefinedBuiltInKernelDescriptor call if any of the conditions
  are violated.

* *Kernel mode properties*: List of kernel mode
   properties (cl_dbk_mode_properties) the kernel recognizes. The
   properties can be used to tweak certain implementation details and
   behaviors in the kernel execution. If a property not listed in the
   DBK entry is fed to clCreateDefinedBuiltInKernelDescriptor call,
   then implementation must return CL_DKB_UNSUPPORTED_MODE_PROPERTY.

[caption="Table A.I.1. "]
.Standard Built-in Kernels and Their Semantics. *The table has been populated with a small set of non-trivial example entries which are subject to change and the list to expand during drafting.*
|===
| Name: *khr_matmul*
| *Kernel Attributes*
a|
Fields of the `cl_dkb_attributes_matmul` structure:

. cl_tensor A: Tensor description for input matrix A.
. cl_tensor B: Tensor description for input matrix B.
. cl_tensor R: Tensor description for output matrix C.
. cl_int transposeA: Non-zero transposes A matrix.
. cl_int transposeB: Non-zero transposes B matrix.
| *Kernel Arguments*
a|
. cl_tensor A: Matrix A (read only).
. cl_tensor B: Matrix B (read only).
. cl_tensor R: Output matrix. (write only).
| *Description*
a|
Performs (batched) matrix multiplication: `R = trans(A) * trans(B)`,
where `A`, `B` and `R` are tensors with at least rank two. The
`trans()` is a configurable transpose operation.

Last two dimensions of the tensors are treated as operands to the
matric multiplication and rest of the dimensions are treated as batch
dimensions.

Operations of the matrix muliplication are performed in the precision
of the `elementof\(R)`.

If an overflow occurs in the accumulation of the products, then `R`
tensor's result will be undefined.

| *Attribute validation rules*
a|

* `rankof(A) == rankof(B) >= 2`.
* Let `shapeof(A~t~) == (b..., m, k)` and `shapeof(B~t~) = (b..., k,
  n)` of tensors `A` and `B`, respectively, after possible tranposing.
  `shapeof\(R)` must be `(b..., m, n)`.
* `elementof(A) == elementof(B)`
* `elemkindof\(R) == elemkindof(A)`
* `elementof\(R) == elementof(A)` or `elementof(A)` is promotable to
  `elementof\(R)` without loss of meaning.
// E.g. cl_int -> cl_uint: loses negative values
| *Kernel mode properties*
a|
This DBK accepts the following properties:

* CL_DBK_PROPERTY_MAX_RELATIVE_ERROR: Unset property defaults to positive infinity.
|
| Name: *khr_leaky_relu*
| *Kernel Attributes*
a|
Fields of the `cl_dbk_leaky_relu` structure:

. cl_tensor in: Input tensor description.
. cl_tensor out: Output tensor description.
. cl_float alpha: Coefficient of leakage.
| *Kernel arguments*
a|
. cl_tensor in: The input tensor.
. cl_tensor out: The output tensor.
| *Description*
a|
Applies operation `alpha * x if x < 0 else x` on all
elements of the `in` tensor.

If target device does not support denormals, then `alpha` is flushed
to zero before the operation is applied.

| *Kernel mode properties*
| N/A
| *Attribute validation rules*
a|
* `shapeof(in) == shapeof(out)`
* `elementof(in) == elementof(out)`
* `alpha` must be a finite value.
|===

==== Launching DBKs from the Device Side ====

DBKs are primarily meant to be launched as kernel commands via
host-side command queues.  Optionally, they can be callable from
device-side via `enqueue_kernel`:

TBC. This probably needs device-side function corresponding to
clCreateDefinedBuiltInKernelDescriptor.

==== Sample Code ====

[source,c]
----
constexpr size_t b = 64, m = 100, n = 200, k = 50;
cl_int err;
cl_tensor lhs_tensor = clCreateTensor(context, nullptr, 3, {b, m, k}, CL_TENSOR_FLOAT, err);
cl_tensor rhs_tensor = clCreateTensor(context, nullptr, 3, {b, k, n}, CL_TENSOR_FLOAT, err);
cl_tensor res_tensor = clCreateTensor(context, nullptr, 3, {b, m, n}, CL_TENSOR_FLOAT, err);

cl_dkb_attributes_matmul matmul_attrs = {
  lhs_tensor, rhs_tensor, res_tensor, 1, 0 // = Transpose lhs tensor
};

cl_dbk_mode_properties matmul_props = {
  // Request a matmul instance that meets this precision.
  CL_DBK_PROPERTY_MAX_RELATIVE_ERROR, 100, // in ULPs.
};

std::vector<cl_dbk_descriptor> kernel_descriptions;
cl_dbk_descriptor matmul_desc =
  clCreateDefinedBuiltInKernelDescriptor(
  context, num_devices, device_list,
  CL_DBK_MATMUL, &matmul_attrs, &matmul_props, &err);

} else if (err == CL_DBK_UNAVAILABLE) {
  // Kernel attributes are valid but the kernel is not supported in at least
  // one of the devices.
  ...
} else if (err == CL_DBK_UNMET_MAX_RELATIVE_ERROR) {
  // E.g. Kernel is supported but is not precise enough.
  ...
} else if (err == CL_DBK_UNSUPPORTED_MODE_PROPERTY) {
  // cl_dbk_mode_properties has a property not listed in the description of the
  // defined built-in kernel.
  ...
} else
  kernel_descriptions.push_back(matmul_desc);

...

cl_program dbk_lib = clCreateProgramWithDefinedBuiltInKernels(
  context, kernel_descriptions.size(), kernel_descriptors.data(), err);

...

cl_kernel matmul_kernel = clCreateDefinedBuiltinKernel(
  dkb_lib, matmul_desc, &err);

// Set tensor kernel arguments before binding storage to the tensors. This
// gives clCreateBufferWithProperties() opportunity to reason about tensors'
// uses for determining the optimal memory layout (opaque to application) and
// the space needed for the tensors.
clSetKernelArg(matmul_kernel, 0, sizeof(cl_tensor_t), &lhs_tensor);
clSetKernelArg(matmul_kernel, 1, sizeof(cl_tensor_t), &rhs_tensor);
clSetKernelArg(matmul_kernel, 2, sizeof(cl_tensor_t), &res_tensor);

// Allocate storage for tensors.
cl_mem lhs_mem = clCreateBufferWithProperties(
  context, {CL_MEM_BIND_TO_TENSOR, lhs_tensor, 0}, CL_MEM_READ_ONLY, 0, nullptr, &err);
cl_mem rhs_mem = clCreateBufferWithProperties(
  context, {CL_MEM_BIND_TO_TENSOR, rhs_tensor, 0}, CL_MEM_READ_ONLY, 0, nullptr, &err);
cl_mem res_mem = clCreateBufferWithProperties(
  context, {CL_MEM_BIND_TO_TENSOR, res_tensor, 0}, CL_MEM_WRITE_ONLY, 0, nullptr, &err);

// Transfer data to input tensors, execute DBK, and import results
// from the output tensor.

std::vector<float> lhs_data = ...;
std::vector<float> rhs_data = ...;
std::vector<float> res_data(b * m * n);

clEnqueueExportToTensor(cmd_q, lhs_tensor, false, {0, 0, 0}, {0, 0, 0}, {b, m, k},
  nullptr, nullptr, lhs_data.data(), 0, nullptr, nullptr)
clEnqueueExportToTensor(cmd_q, rhs_tensor, false, {0, 0, 0}, {0, 0, 0}, {b, k, n},
  nullptr, nullptr, rhs_data.data(), 0, nullptr, nullptr)
clEnqueueNDRangeKernel(cmd_q, matmul_kernel, 0, NULL, NULL, NULL, 0, NULL, NULL);
clEnqueueImportFromTensor(
  cmd_q, res_tensor, false,  {0, 0, 0}, {0, 0, 0}, {b, m, n},
  nullptr, nullptr, res_data.data(), 0, nullptr, nullptr);
----

=== Open questions

. Should we enable launching DBKs from the device side without requiring device-side enqueue? The main problem is those with NDRange as they are not simple single-WI helper functions.
+
--
*UNRESOLVED*

--

. Should the NDRange be used at all in DBKs? It feels sort of unnatural as typically the NDRange is used to imply SPMD parallelism while the hardware/firmware is free to choose whatever parallelization strategy to implement the function. On the other hand, similar applies to software kernel launches as the NDRange-launched work-items can be executed serially if adhering to barrier semantics.
+
--
*UNRESOLVED*

--

. Different accelerators prefer different channel orders (NHWC vs. NCHW...) for the processed data. Should the channel order be passed as a DBK argument (like in the example GEMM's row/column order) or is it better to have different DBK variations for each?
+
--
*UNRESOLVED*

--

. How to denote preference? Some of the DBKs are more efficient on a given device as they map more naturally to the underlying HW accelerator, but the slower variations (for example, with unoptimal channel order in NN accelerators) might be still beneficially accelerated.
+
--
*UNRESOLVED*

--

. Since the defined built-in kernel concept is basically just a C-like API inside another API, should it be made more generic and thus directly usable for SYCL and Vulkan as well?
+
--
*UNRESOLVED*

--

. What other DBK mode properties we should have? Here are some ideas:
** Perform accumulation with saturation.
** Finite math only
** Flush denormals to zero.
** data layout preferences (NHWC for convolution).
--
*UNRESOLVED*
--
